## ▶ Day 09
 
### Your First Machine Learning Model
You’ll create a machine learning model using the scikit-learn library, one of the most popular and efficient tools for data analysis.

Along the way, you’ll learn some basic techniques for working with very large datasets. These skills are especially important for modern data scientists, who often work with “big data” containing millions of variables ― many more than a human can conceivably understand! Thankfully, machines excel at discovering useful patterns in datasets that are too large for humans to wrap their heads around. :)

가장 인기 있고 효율적인 데이터 분석 도구 중 하나인 sikit-learn 라이브러리를 사용하여 머신러닝 모델을 만들 수 있습니다. 이 과정에서 대규모 데이터셋을 사용하기 위한 몇 가지 기술을 배우게 됩니다. 머신러닝은 인간이 머리로 해결하기에 너무 큰 데이터셋에서 유용한 패턴을 발견하는 데 탁월합니다.

### Model Validation
Once you have built a model, how good is it? How exactly should you judge how close the model’s predictions are to what actually happened? You’ll use model validation to measure the quality of your model.

모델을 만들고 나면 얼마나 좋은지, 모델의 예측이 실제 일어난 일에 얼마나 가까운지 등은 어떻게 판단해야 할까요? 모델 검증을 사용하여 모델의 품질을 측정합니다.
 
## ▶ Day10
 
### Underfitting and Overfitting
You’ll learn about the fundamental concepts of underfitting and overfitting. Then you'll apply these ideas to gain a deep understanding of why some models succeed and others fail. This knowledge will make you much more efficient at discovering highly accurate machine learning models.

과소적합, 과대적합 파트에서는 과적합의 기본 개념에 대해 배울 것입니다. 그런 다음 이러한 아이디어를 적용하여 일부 모델은 성공적인 반면, 다른 모델은 실패하는 이유를 깊게 이해하게 됩니다. 이러한 지식은 더 정확한 머신러닝 학습 모델을 효율적으로 발견하는데에 도움이 됩니다.

### Random Forests
You’ll learn all about random forests, another machine learning model you can add to your growing toolkit. Then, put your new knowledge to use immediately by building your own random forest model that exceeds the performance of the models that you’ve built so far!

또 다른 머신러닝 모델인 랜덤포레스트에 대한 모든 것을 배웁니다. 지금까지 구축한 모델의 성능을 능가하는 자신만의 랜덤포레스트 모델을 구축하게 됩니다.
 
## ▶ Day11
 
### Machine Learning Competitions
One way to further improve your skills is to participate in machine learning competitions. You’ll create and submit your predictions to a Kaggle competition.

여러분의 능력을 더욱 향상시키는 방법 중 한 가지는 머신러닝 대회에 참여하는 것입니다. 캐글 대회에 예측결과를 제출합니다.
 
## ▶ Day12
 
### Missing Values
Most machine learning libraries (including scikit-learn) give an error if you try to build a model using data with missing values. In "Missing Values", you’ll learn about three different approaches for dealing with missing values in your data.

대부분의 머신러닝 라이브러리(scikit-learn 포함)는 결측값이 있는 데이터를 사용하여 모델을 구축하려고 하면 오류가 발생합니다. "Missing Values" 파트에서는 데이터의 결측값을 처리하는 세 가지 방법에 대해 알아봅니다.

### Categorical Variables
A categorical variable is a variable that takes only a limited number of values, and it’s common to encounter them in data. Learn how to work with them in "Categorical Variables".

범주형 변수는 제한된 수의 값만 사용하는 변수이며, 데이터에서 흔히 볼 수 있습니다. "Categorical Variables"파트에서 이러한 변수를 사용하는 방법에 대해 알아봅니다.
 
## ▶ Day 13
 
### Pipelines
You’ll learn a simple way to keep your data preprocessing and modeling code organized.

데이터 사전 처리 및 모델링 코드를 구성하는 간단한 방법을 배울 수 있습니다.

### Cross-Validation
You’ll explore a more advanced validation technique that gives a better measure of model performance.

모델 성능을 더 잘 측정할 수 있는 고급 검증 기법을 살펴봅니다.
 
## ▶ Day 14
 
### XGBoost
You will learn how to build and optimize models with gradient boosting. This method dominates many Kaggle competitions and achieves state-of-the-art results on a variety of datasets.

그라데이션 부스팅으로 모델을 구축하고 최적화하는 방법에 대해 배울 것입니다. 이 방법은 많은 캐글 대회에서 우위를 차지하며 다양한 데이터셋에서 좋은 결과를 달성합니다.

### Data Leakage
You will learn what data leakage is and how to prevent it. If you don't know how to prevent it, leakage will come up frequently, and it will ruin your models in subtle and dangerous ways. So, this is one of the most important concepts for practicing data scientists.

데이터 유출이 무엇이고 이를 방지하는 방법은 무엇인지에 대해 알아봅니다. 예방법을 모르면 데이터 누수가 잦아지고, 미묘하고 위험한 방법으로 모델을 망가뜨릴 수 있습니다. Data Leakage는 데이터 사이언티스트를 위한 가장 중요한 개념 중 하나입니다.
